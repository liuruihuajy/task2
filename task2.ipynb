{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf78720-5881-4978-8c22-5b9d793aa9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\torch_gpu1.13\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from torchvision.models import resnet50  \n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ce25f59-d039-46ba-9e18-230ad1e86161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir='runs/result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae0ebdec-46de-4496-a2fc-f44a0ee8be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. 加载并预处理CIFAR-100数据集\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ViT期望的输入尺寸\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d37a0e4f-6375-4bf8-8c8f-b79af47c3fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.cifar.CIFAR100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82a44734-560f-48e1-ae47-7a0523b048b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04e4bcb3-d860-43e0-8887-f0448b377992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设我们只想要前50%的样本  \n",
    "num_samples = len(trainset)  \n",
    "indices = list(range(num_samples))  \n",
    "split = int(0.05 * num_samples)  \n",
    "subset_indices = indices[:split]  \n",
    "  \n",
    "# 使用SubsetRandomSampler来随机选择样本（但在这里我们只是按顺序选择）  \n",
    "subset_sampler = SubsetRandomSampler(subset_indices)  \n",
    "  \n",
    "num_test_samples = len(testset)\n",
    "indices = list(range(num_test_samples))  \n",
    "split = int(0.02 * num_test_samples)  \n",
    "test_subset_indices = indices[:split] \n",
    "\n",
    "test_subset_sampler = SubsetRandomSampler(test_subset_indices)  \n",
    "\n",
    "# 创建DataLoader  \n",
    "trainloader = DataLoader(trainset, batch_size=64, sampler=subset_sampler) \n",
    "testloader = DataLoader(testset, batch_size=64, sampler=test_subset_sampler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13742824-d724-404e-bd57-03da8ed66cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.1 定义ViT模型\n",
    "weights = ViT_B_16_Weights.DEFAULT\n",
    "model = vit_b_16(weights=weights)\n",
    "model.heads[0] = nn.Linear(model.heads[0].in_features, 100)  # 修改分类头为100类\n",
    "\n",
    "# 如果有可用的GPU，则将模型转到GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 3.1.2. 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea69a36e-2b66-4e6a-882f-b9e982d63ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1.1 定义CNN模型  \n",
    "class SimpleCNN(nn.Module):  \n",
    "    def __init__(self, num_classes=100):  \n",
    "        super(SimpleCNN, self).__init__()  \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)  \n",
    "        self.relu = nn.ReLU(inplace=True)  \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)  \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  \n",
    "        self.fc = nn.Linear(64 * 7 * 7, num_classes)  # 假设输入图像是224x224，经过两次卷积和池化后，特征图大小为7x7  \n",
    "  \n",
    "    def forward(self, x):  \n",
    "        x = self.conv1(x)  \n",
    "        x = self.relu(x)  \n",
    "        x = self.maxpool(x)  \n",
    "        x = self.conv2(x)  \n",
    "        x = self.relu(x)  \n",
    "        x = self.maxpool(x)  \n",
    "        x = x.view(x.size(0), -1)  # 展平特征图  \n",
    "        x = self.fc(x)  \n",
    "        return x  \n",
    "# 实例化模型  \n",
    "cnn_model = SimpleCNN(num_classes=100)  \n",
    "  \n",
    "# 如果有可用的GPU，则将模型转到GPU  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  \n",
    "cnn_model.to(device)  \n",
    "  \n",
    "# 4.1.2 定义损失函数和优化器  \n",
    "cnn_criterion = nn.CrossEntropyLoss()  \n",
    "cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "320a0bd4-1836-447c-b752-b2561ecf64e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, batch:3, loss: 1.454\n",
      "epoch:1, batch:6, loss: 1.469\n",
      "epoch:1, batch:9, loss: 1.413\n",
      "epoch:1, batch:12, loss: 1.432\n",
      "epoch:1, batch:15, loss: 1.415\n",
      "epoch:1, batch:18, loss: 1.391\n",
      "epoch:1, batch:21, loss: 1.389\n",
      "epoch:1, batch:24, loss: 1.401\n",
      "epoch:1, batch:27, loss: 1.388\n",
      "epoch:1, batch:30, loss: 1.387\n",
      "epoch:1, batch:33, loss: 1.392\n",
      "epoch:1, batch:36, loss: 1.392\n",
      "epoch:1, batch:39, loss: 1.404\n",
      "epoch:2, batch:3, loss: 1.373\n",
      "epoch:2, batch:6, loss: 1.368\n",
      "epoch:2, batch:9, loss: 1.379\n",
      "epoch:2, batch:12, loss: 1.373\n",
      "epoch:2, batch:15, loss: 1.367\n",
      "epoch:2, batch:18, loss: 1.369\n",
      "epoch:2, batch:21, loss: 1.373\n",
      "epoch:2, batch:24, loss: 1.378\n",
      "epoch:2, batch:27, loss: 1.364\n",
      "epoch:2, batch:30, loss: 1.370\n",
      "epoch:2, batch:33, loss: 1.393\n",
      "epoch:2, batch:36, loss: 1.361\n",
      "epoch:2, batch:39, loss: 1.380\n",
      "epoch:3, batch:3, loss: 1.340\n",
      "epoch:3, batch:6, loss: 1.369\n",
      "epoch:3, batch:9, loss: 1.357\n",
      "epoch:3, batch:12, loss: 1.354\n",
      "epoch:3, batch:15, loss: 1.369\n",
      "epoch:3, batch:18, loss: 1.363\n",
      "epoch:3, batch:21, loss: 1.373\n",
      "epoch:3, batch:24, loss: 1.370\n",
      "epoch:3, batch:27, loss: 1.351\n",
      "epoch:3, batch:30, loss: 1.365\n",
      "epoch:3, batch:33, loss: 1.356\n",
      "epoch:3, batch:36, loss: 1.358\n",
      "epoch:3, batch:39, loss: 1.356\n",
      "epoch:4, batch:3, loss: 1.332\n",
      "epoch:4, batch:6, loss: 1.338\n",
      "epoch:4, batch:9, loss: 1.322\n",
      "epoch:4, batch:12, loss: 1.331\n",
      "epoch:4, batch:15, loss: 1.324\n",
      "epoch:4, batch:18, loss: 1.350\n",
      "epoch:4, batch:21, loss: 1.340\n",
      "epoch:4, batch:24, loss: 1.354\n",
      "epoch:4, batch:27, loss: 1.335\n",
      "epoch:4, batch:30, loss: 1.314\n",
      "epoch:4, batch:33, loss: 1.340\n",
      "epoch:4, batch:36, loss: 1.292\n",
      "epoch:4, batch:39, loss: 1.290\n",
      "epoch:5, batch:3, loss: 1.279\n",
      "epoch:5, batch:6, loss: 1.303\n",
      "epoch:5, batch:9, loss: 1.323\n",
      "epoch:5, batch:12, loss: 1.320\n",
      "epoch:5, batch:15, loss: 1.287\n",
      "epoch:5, batch:18, loss: 1.285\n",
      "epoch:5, batch:21, loss: 1.343\n",
      "epoch:5, batch:24, loss: 1.309\n",
      "epoch:5, batch:27, loss: 1.315\n",
      "epoch:5, batch:30, loss: 1.304\n",
      "epoch:5, batch:33, loss: 1.310\n",
      "epoch:5, batch:36, loss: 1.303\n",
      "epoch:5, batch:39, loss: 1.289\n",
      "epoch:6, batch:3, loss: 1.261\n",
      "epoch:6, batch:6, loss: 1.285\n",
      "epoch:6, batch:9, loss: 1.278\n",
      "epoch:6, batch:12, loss: 1.253\n",
      "epoch:6, batch:15, loss: 1.256\n",
      "epoch:6, batch:18, loss: 1.282\n",
      "epoch:6, batch:21, loss: 1.303\n",
      "epoch:6, batch:24, loss: 1.309\n",
      "epoch:6, batch:27, loss: 1.287\n",
      "epoch:6, batch:30, loss: 1.247\n",
      "epoch:6, batch:33, loss: 1.292\n",
      "epoch:6, batch:36, loss: 1.268\n",
      "epoch:6, batch:39, loss: 1.289\n",
      "epoch:7, batch:3, loss: 1.239\n",
      "epoch:7, batch:6, loss: 1.229\n",
      "epoch:7, batch:9, loss: 1.300\n",
      "epoch:7, batch:12, loss: 1.259\n",
      "epoch:7, batch:15, loss: 1.263\n",
      "epoch:7, batch:18, loss: 1.288\n",
      "epoch:7, batch:21, loss: 1.277\n",
      "epoch:7, batch:24, loss: 1.250\n",
      "epoch:7, batch:27, loss: 1.227\n",
      "epoch:7, batch:30, loss: 1.256\n",
      "epoch:7, batch:33, loss: 1.258\n",
      "epoch:7, batch:36, loss: 1.227\n",
      "epoch:7, batch:39, loss: 1.250\n",
      "epoch:8, batch:3, loss: 1.221\n",
      "epoch:8, batch:6, loss: 1.220\n",
      "epoch:8, batch:9, loss: 1.234\n",
      "epoch:8, batch:12, loss: 1.226\n",
      "epoch:8, batch:15, loss: 1.208\n",
      "epoch:8, batch:18, loss: 1.261\n",
      "epoch:8, batch:21, loss: 1.214\n",
      "epoch:8, batch:24, loss: 1.217\n",
      "epoch:8, batch:27, loss: 1.226\n",
      "epoch:8, batch:30, loss: 1.171\n",
      "epoch:8, batch:33, loss: 1.235\n",
      "epoch:8, batch:36, loss: 1.251\n",
      "epoch:8, batch:39, loss: 1.240\n",
      "epoch:9, batch:3, loss: 1.158\n",
      "epoch:9, batch:6, loss: 1.199\n",
      "epoch:9, batch:9, loss: 1.182\n",
      "epoch:9, batch:12, loss: 1.233\n",
      "epoch:9, batch:15, loss: 1.191\n",
      "epoch:9, batch:18, loss: 1.221\n",
      "epoch:9, batch:21, loss: 1.218\n",
      "epoch:9, batch:24, loss: 1.205\n",
      "epoch:9, batch:27, loss: 1.218\n",
      "epoch:9, batch:30, loss: 1.257\n",
      "epoch:9, batch:33, loss: 1.211\n",
      "epoch:9, batch:36, loss: 1.211\n",
      "epoch:9, batch:39, loss: 1.195\n",
      "epoch:10, batch:3, loss: 1.181\n",
      "epoch:10, batch:6, loss: 1.158\n",
      "epoch:10, batch:9, loss: 1.199\n",
      "epoch:10, batch:12, loss: 1.159\n",
      "epoch:10, batch:15, loss: 1.174\n",
      "epoch:10, batch:18, loss: 1.167\n",
      "epoch:10, batch:21, loss: 1.204\n",
      "epoch:10, batch:24, loss: 1.168\n",
      "epoch:10, batch:27, loss: 1.144\n",
      "epoch:10, batch:30, loss: 1.164\n",
      "epoch:10, batch:33, loss: 1.197\n",
      "epoch:10, batch:36, loss: 1.206\n",
      "epoch:10, batch:39, loss: 1.197\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# 5. 训练模型\n",
    "val_acc_list = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "for epoch in range(10):  # 遍历数据集多次\n",
    "    train_loss = 0 \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cnn_optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        cnn_outputs = cnn_model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        cnn_loss = cnn_criterion(cnn_outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        cnn_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        cnn_optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_loss   += loss.item()\n",
    "        if i % 3 == 2:  # 每20个批次打印一次\n",
    "            print(\"epoch:\"+f'{epoch + 1}, batch:{i + 1}, loss: {running_loss / 10:.3f}')\n",
    "            running_loss = 0.0\n",
    "        # print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss}')\n",
    "\n",
    "    train_loss_list.append(train_loss / len(trainloader))\n",
    "    val_loss = 0\n",
    "    # 6. 评估模型\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_acc_list.append(correct / total)\n",
    "    \n",
    "    writer.add_scalar(tag=\"train_accuracy\", \n",
    "                      scalar_value=correct / total, \n",
    "                      global_step=epoch  \n",
    "                      )\n",
    "    \n",
    "    writer.add_scalar(tag=\"train_loss\", \n",
    "                      scalar_value=train_loss / len(trainloader),  \n",
    "                      global_step=epoch  \n",
    "                      )\n",
    "    writer.add_scalar(tag=\"loss\",\n",
    "                      scalar_value=val_loss,  \n",
    "                      global_step=epoch  \n",
    "                      )\n",
    "    train_loss = 0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8126eb-8774-4614-a59a-6ab94fe7f37e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_gpu",
   "language": "python",
   "name": "torch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
