# 在CIFAR-100数据集上比较基于Transformer和CNN的图像分类模型
## 1. 模型介绍
### 1.1 CNN模型
卷积神经网络（CNN）是计算机视觉任务中广泛使用的网络结构，它通过卷积层、池化层、全连接层等组件来提取图像中的特征。在本次实验中，我们实现了一个具有相近参数量的CNN模型，该模型通过堆叠多个卷积块（每个块包含卷积层、批量归一化层和ReLU激活函数）来构建，并在最后加入全局平均池化层和全连接层进行分类。

### 1.2 Transformer模型
Transformer模型最初是为自然语言处理任务设计的，但近年来在图像分类任务中也展现出了强大的性能。我们实现了一个基于Vision Transformer（ViT）的模型，它将图像分割成一系列小块（patches），并将这些小块视为序列输入到Transformer编码器中进行处理。通过自注意力机制，Transformer模型能够捕获图像中的全局依赖关系。
- 模型权值：https://huggingface.co/google-bert/bert-base-uncased
## 2. 数据集介绍
CIFAR-100是一个包含100个类别、每个类别600张32x32彩色图像的数据集。这些图像被分为50000张训练图像和10000张测试图像。CIFAR-100数据集具有较大的类别数和较复杂的图像内容，为图像分类任务提供了很好的挑战。

## 3. 实验设置
## 3.1 训练测试集划分
我们将CIFAR-100数据集的训练集用于训练模型，测试集用于评估模型的性能。在训练过程中，我们还使用了验证集来监控模型的训练效果并进行超参数调整。
### 3.2 网络结构
对于CNN模型，我们采用了多个卷积块堆叠的方式构建网络。对于Transformer模型，我们使用了基于ViT的架构，并根据CIFAR-100数据集的特点进行了适当的调整。两个模型都具有相近的参数量，以确保公平的比较。
### 3.3 训练参数
Batch size: 128 <br/>
Learning rate: 初始值为0.001，采用余弦衰减策略<br/>
优化器: AdamW<br/>
Iteration/Epoch: 训练50个epoch<br/>
Loss function: 交叉熵损失函数<br/>
数据增强: 包括随机裁剪、水平翻转和CutMix<br/>
### 3.4 评价指标
我们使用准确率（Accuracy）和损失函数作为评价模型性能的主要指标。在测试集上计算模型的准确率，以评估其在未见过的数据上的泛化能力。
## 4. 训练过程可视化
在训练过程中，我们记录了CNN和Transformer模型在训练集和验证集上的准确率变化曲线。通过可视化这些曲线，我们可以观察到模型在训练过程中的性能提升和过拟合情况。此外，我们还记录了训练过程中的损失函数值变化，以了解模型在优化过程中的收敛情况。


### 5. 实验结果
经过50个epoch的训练，我们在CIFAR-100测试集上评估了CNN和Transformer模型的性能。实验结果表明，在两个模型都具有相近参数量的情况下，Transformer模型在CIFAR-100数据集上取得了更高的准确率。这可能是由于Transformer模型通过自注意力机制能够捕获图像中的全局依赖关系，从而更好地提取和利用图像中的特征信息。
此外，我们还尝试了不同的超参数组合，包括学习率、batch size等，以尽可能提升各架构在CIFAR-100上的性能。通过调整超参数，我们观察到模型性能的一定提升，但并未改变Transformer模型相对于CNN模型的优势地位。
综上所述，基于Transformer的图像分类模型在CIFAR-100数据集上展现出了优于CNN模型的性能。这一结果为我们今后在图像分类任务中选择合适的网络架构提供了一定的参考依据。
